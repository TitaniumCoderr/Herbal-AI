{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KbzA3PtKR5q",
        "outputId": "0598199e-b1d3-49ca-eef1-7a7552df7a2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from tensorflow.keras import callbacks, optimizers\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import tensorflow_datasets as tfds #imported to get the plant_village dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras.layers import GlobalAvgPool2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiMBFLYdKUPb",
        "outputId": "72d46bf0-88fd-49fc-932e-6dc57bda140b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22800 images belonging to 38 classes.\n",
            "Found 9500 images belonging to 38 classes.\n",
            "Found 5700 images belonging to 38 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4483s\u001b[0m 90s/step - accuracy: 0.1092 - loss: 3.8733 - val_accuracy: 0.5549 - val_loss: 2.6915\n",
            "Epoch 2/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2704s\u001b[0m 57s/step - accuracy: 0.4711 - loss: 1.9430 - val_accuracy: 0.7156 - val_loss: 2.0193\n",
            "Epoch 3/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2693s\u001b[0m 58s/step - accuracy: 0.6316 - loss: 1.3075 - val_accuracy: 0.7847 - val_loss: 1.5056\n",
            "Epoch 4/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2689s\u001b[0m 57s/step - accuracy: 0.7190 - loss: 1.0033 - val_accuracy: 0.8291 - val_loss: 1.1131\n",
            "Epoch 5/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2689s\u001b[0m 58s/step - accuracy: 0.7657 - loss: 0.8150 - val_accuracy: 0.8570 - val_loss: 0.8301\n",
            "Epoch 6/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2659s\u001b[0m 58s/step - accuracy: 0.7979 - loss: 0.6915 - val_accuracy: 0.8798 - val_loss: 0.6295\n",
            "Epoch 7/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2689s\u001b[0m 58s/step - accuracy: 0.8176 - loss: 0.6162 - val_accuracy: 0.8956 - val_loss: 0.4955\n",
            "Epoch 8/10\n",
            "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6:53\u001b[0m 46s/step - accuracy: 0.8349 - loss: 0.5684"
          ]
        }
      ],
      "source": [
        "base_folder = \"/content/drive/My Drive/DL_Dataset3\"\n",
        "train_dir = os.path.join(base_folder, \"train\")\n",
        "test_dir = os.path.join(base_folder, \"test\")\n",
        "validate_dir = os.path.join(base_folder, \"validate\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def img_data(dir_path, target_size, batch_size, class_lst, preprocess_func=None):\n",
        "    gen_object = ImageDataGenerator(preprocessing_function=preprocess_func) if preprocess_func else ImageDataGenerator()\n",
        "    return gen_object.flow_from_directory(\n",
        "        dir_path,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='sparse',\n",
        "        classes=class_lst,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "class_list = os.listdir(train_dir)  \n",
        "\n",
        "train_data_gen = img_data(os.path.join(base_folder, \"train\"), (224, 224), 500, class_list, tf.keras.applications.efficientnet.preprocess_input)\n",
        "test_data_gen = img_data(os.path.join(base_folder, \"test\"), (224, 224), 500, class_list, tf.keras.applications.efficientnet.preprocess_input)\n",
        "valid_data_gen = img_data(os.path.join(base_folder, \"validate\"), (224, 224), 500, class_list, tf.keras.applications.efficientnet.preprocess_input)\n",
        "\n",
        "# Load and set up EfficientNetB0 model\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling=None\n",
        ")\n",
        "base_model.trainable = False  \n",
        "\n",
        "# Build and compile the model\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    GlobalAvgPool2D(),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),  \n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),  \n",
        "    Dense(len(class_list), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  \n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define callbacks and train the model\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
        "save_ckpt = ModelCheckpoint(\"EffNetModel2.keras\", save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "model.fit(\n",
        "    train_data_gen,\n",
        "    validation_data=valid_data_gen,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop, save_ckpt]\n",
        ")\n",
        "\n",
        "print('model saved')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
