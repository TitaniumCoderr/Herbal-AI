{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21pVCkl0RHjF",
        "outputId": "b61082dd-b350-45a0-a07b-8e4c0a759296"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Conv2D,GlobalAvgPool2D, Input\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from tensorflow.keras import callbacks, optimizers\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import tensorflow_datasets as tfds #imported to get the plant_village dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split #split the data\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "%cd drive/MyDrive/\n",
        "\n",
        "#listing the classes in the dataset\n",
        "for i in os.listdir(\"Plant_Dataset\"):\n",
        "  print(i, len(os.listdir(\"Plant_Dataset/\"+i)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "279LDL2cVodv",
        "outputId": "91bae406-26d7-47fd-959b-233632d800ea"
      },
      "outputs": [],
      "source": [
        "# Create DL_dataset folder with train, test, and validate subfolders\n",
        "#base_folder = \"DL_Dataset3\"\n",
        "#for subfolder in [\"train\", \"test\", \"validate\"]:\n",
        "    #os.makedirs(os.path.join(base_folder, subfolder), exist_ok=True)\n",
        "    #print(os.path.join(base_folder, subfolder))\n",
        "\n",
        "# Loop through the dataset in the Plant_Dataset folder and split it\n",
        "#for class_folder in os.listdir(\"Plant_Dataset\"):\n",
        "    # Create subdirectories for each class in train, test, and validate folders\n",
        "    #os.makedirs(os.path.join(base_folder, \"train\", class_folder), exist_ok=True)\n",
        "    #os.makedirs(os.path.join(base_folder, \"test\", class_folder), exist_ok=True)\n",
        "    #os.makedirs(os.path.join(base_folder, \"validate\", class_folder), exist_ok=True)\n",
        "\n",
        "    # Move images to train, test, and validate folders\n",
        "    #images = os.listdir(os.path.join(\"Plant_Dataset\", class_folder))\n",
        "    #for img in images[:600]:\n",
        "        #shutil.copy(os.path.join(\"Plant_Dataset\", class_folder, img), os.path.join(base_folder, \"train\", class_folder, img))\n",
        "    #for img in images[600:850]:\n",
        "        #shutil.copy(os.path.join(\"Plant_Dataset\", class_folder, img), os.path.join(base_folder, \"test\", class_folder, img))\n",
        "    #for img in images[850:1000]:\n",
        "        #shutil.copy(os.path.join(\"Plant_Dataset\", class_folder, img), os.path.join(base_folder, \"validate\", class_folder, img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN3Yl5N_gQCC",
        "outputId": "d2650e4a-954d-42fc-93cc-553b8dae653d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22800 images belonging to 38 classes.\n",
            "Found 9500 images belonging to 38 classes.\n",
            "Found 5700 images belonging to 38 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8664s\u001b[0m 167s/step - accuracy: 0.6392 - loss: 1.4572 - val_accuracy: 0.8937 - val_loss: 0.3436\n",
            "Epoch 2/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1588s\u001b[0m 34s/step - accuracy: 0.9334 - loss: 0.2134 - val_accuracy: 0.9188 - val_loss: 0.2708\n",
            "Epoch 3/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1638s\u001b[0m 34s/step - accuracy: 0.9580 - loss: 0.1400 - val_accuracy: 0.9139 - val_loss: 0.2840\n",
            "Epoch 4/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1601s\u001b[0m 34s/step - accuracy: 0.9730 - loss: 0.1031 - val_accuracy: 0.9216 - val_loss: 0.2475\n",
            "Epoch 5/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1639s\u001b[0m 34s/step - accuracy: 0.9768 - loss: 0.0834 - val_accuracy: 0.9146 - val_loss: 0.2974\n",
            "Epoch 6/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1652s\u001b[0m 34s/step - accuracy: 0.9859 - loss: 0.0617 - val_accuracy: 0.9367 - val_loss: 0.2010\n",
            "Epoch 7/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1581s\u001b[0m 34s/step - accuracy: 0.9912 - loss: 0.0447 - val_accuracy: 0.9242 - val_loss: 0.2541\n",
            "Epoch 8/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1578s\u001b[0m 34s/step - accuracy: 0.9875 - loss: 0.0471 - val_accuracy: 0.9304 - val_loss: 0.2342\n",
            "Epoch 9/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1579s\u001b[0m 34s/step - accuracy: 0.9953 - loss: 0.0285 - val_accuracy: 0.9351 - val_loss: 0.2153\n",
            "Epoch 10/10\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1551s\u001b[0m 33s/step - accuracy: 0.9974 - loss: 0.0222 - val_accuracy: 0.9354 - val_loss: 0.2189\n",
            "model saved\n"
          ]
        }
      ],
      "source": [
        "# Function to create ImageDataGenerator for train, test, and validate datasets\n",
        "def img_data(dir_path, target_size, batch_size, class_lst, preprocess_func=None):\n",
        "    gen_object = ImageDataGenerator(preprocessing_function=preprocess_func) if preprocess_func else ImageDataGenerator()\n",
        "    return gen_object.flow_from_directory(\n",
        "        dir_path,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='sparse',\n",
        "        classes=class_lst,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "# Define class list and initialize data generators using DL_dataset folder\n",
        "base_folder = \"DL_Dataset3\"\n",
        "class_list = os.listdir(os.path.join(base_folder, \"train\"))\n",
        "\n",
        "train_data_gen = img_data(os.path.join(base_folder, \"train\"), (224, 224), 500, class_list, preprocess_input)\n",
        "test_data_gen = img_data(os.path.join(base_folder, \"test\"), (224, 224), 500, class_list, preprocess_input)\n",
        "valid_data_gen = img_data(os.path.join(base_folder, \"validate\"), (224, 224), 500, class_list, preprocess_input)\n",
        "\n",
        "# Load and set up MobileNetV2 model\n",
        "my_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    alpha=1.0,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling=None,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "my_model.trainable = False\n",
        "\n",
        "# Build and compile model\n",
        "model = tf.keras.models.Sequential([\n",
        "    my_model,\n",
        "    GlobalAvgPool2D(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(len(class_list), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks and train the model\n",
        "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
        "save_ckpt = callbacks.ModelCheckpoint(\".myModel2.keras\", save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# Fit model\n",
        "model.fit(\n",
        "    train_data_gen,\n",
        "    validation_data=valid_data_gen,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop, save_ckpt]\n",
        ")\n",
        "\n",
        "print('model saved')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
